{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, sum, hour, month\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Web UI running at: http://DESKTOP-MGIJLCC:4040\n"
     ]
    }
   ],
   "source": [
    "# Khởi tạo Spark Session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WeatherPredictionGBT\") \\\n",
    "    .config(\"spark.ui.port\", \"4040\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# In URL của Web UI để theo dõi\n",
    "print(\"Spark Web UI running at:\", spark.sparkContext.uiWebUrl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Formatted Date: timestamp (nullable = true)\n",
      " |-- Summary: string (nullable = true)\n",
      " |-- Precip Type: string (nullable = true)\n",
      " |-- Temperature (C): double (nullable = true)\n",
      " |-- Apparent Temperature (C): double (nullable = true)\n",
      " |-- Humidity: double (nullable = true)\n",
      " |-- Wind Speed (km/h): double (nullable = true)\n",
      " |-- Wind Bearing (degrees): double (nullable = true)\n",
      " |-- Visibility (km): double (nullable = true)\n",
      " |-- Loud Cover: double (nullable = true)\n",
      " |-- Pressure (millibars): double (nullable = true)\n",
      " |-- Daily Summary: string (nullable = true)\n",
      "\n",
      "+-------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "|     Formatted Date|      Summary|Precip Type|  Temperature (C)|Apparent Temperature (C)|Humidity| Wind Speed (km/h)|Wind Bearing (degrees)|   Visibility (km)|Loud Cover|Pressure (millibars)|       Daily Summary|\n",
      "+-------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "|2006-04-01 05:00:00|Partly Cloudy|       rain|9.472222222222221|      7.3888888888888875|    0.89|           14.1197|                 251.0|15.826300000000002|       0.0|             1015.13|Partly cloudy thr...|\n",
      "|2006-04-01 06:00:00|Partly Cloudy|       rain|9.355555555555558|       7.227777777777776|    0.86|           14.2646|                 259.0|15.826300000000002|       0.0|             1015.63|Partly cloudy thr...|\n",
      "|2006-04-01 07:00:00|Mostly Cloudy|       rain|9.377777777777778|       9.377777777777778|    0.89|3.9284000000000003|                 204.0|           14.9569|       0.0|             1015.94|Partly cloudy thr...|\n",
      "|2006-04-01 08:00:00|Partly Cloudy|       rain| 8.28888888888889|       5.944444444444446|    0.83|           14.1036|                 269.0|15.826300000000002|       0.0|             1016.41|Partly cloudy thr...|\n",
      "|2006-04-01 09:00:00|Mostly Cloudy|       rain|8.755555555555553|       6.977777777777779|    0.83|           11.0446|                 259.0|15.826300000000002|       0.0|             1016.51|Partly cloudy thr...|\n",
      "+-------------------+-------------+-----------+-----------------+------------------------+--------+------------------+----------------------+------------------+----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Total rows: 96453\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Khởi tạo Spark Session\n",
    "spark = SparkSession.builder.appName(\"WeatherPrediction\").getOrCreate()\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "file_path = \"C:/bigdata/weatherHistory.csv\"\n",
    "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Hiển thị schema và một số dòng mẫu\n",
    "df.printSchema()\n",
    "df.show(5)\n",
    "\n",
    "# Kiểm tra số lượng bản ghi\n",
    "print(f\"Total rows: {df.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thêm đặc trưng thời gian\n",
    "df = df.withColumn(\"Hour\", hour(col(\"Formatted Date\")))\n",
    "df = df.withColumn(\"Month\", month(col(\"Formatted Date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, StandardScaler\n",
    "\n",
    "# Mã hóa cột Summary\n",
    "indexer = StringIndexer(inputCol=\"Summary\", outputCol=\"SummaryIndex\")\n",
    "df = indexer.fit(df).transform(df)\n",
    "encoder = OneHotEncoder(inputCols=[\"SummaryIndex\"], outputCols=[\"SummaryVec\"])\n",
    "df = encoder.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn đặc trưng\n",
    "feature_cols = [\"Humidity\", \"Wind Speed (km/h)\", \"Wind Bearing (degrees)\", \n",
    "                \"Visibility (km)\", \"Pressure (millibars)\", \"SummaryVec\", \"Hour\", \"Month\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "final_df = assembler.transform(df).select(col(\"features\"), col(\"Temperature (C)\").alias(\"label\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chuẩn bị dữ liệu học máy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data rows: 77349\n",
      "Test data rows: 19104\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = final_df.randomSplit([0.8, 0.2], seed=42)\n",
    "print(f\"Training data rows: {train_data.count()}\")\n",
    "print(f\"Test data rows: {test_data.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-26.702665789905367,-0.12341673000413964,0.0008594462699007523,0.3479277762958408,0.0,1.2441817679683755,0.2775126324074202,0.0,0.0,-1.017236717999512,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.5454064319080595,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004261462065913704,0.4350390034971129]\n",
      "Intercept:  25.83523019866581\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Khởi tạo mô hình Linear Regression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"label\", maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "# In hệ số và intercept của mô hình\n",
    "print(\"Coefficients: \", lr_model.coefficients)\n",
    "print(\"Intercept: \", lr_model.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+------------------+\n",
      "|            features|             label|        prediction|\n",
      "+--------------------+------------------+------------------+\n",
      "|(33,[0,1,2,3,4,5,...| 39.58888888888889|28.551960211383097|\n",
      "|(33,[0,1,2,3,4,5,...| 38.71666666666667|28.304873601684704|\n",
      "|(33,[0,1,2,3,4,5,...|38.983333333333334| 27.92832382158092|\n",
      "|(33,[0,1,2,3,4,5,...|38.705555555555556|  27.7919252503512|\n",
      "|(33,[0,1,2,3,4,5,...| 28.81666666666667|28.079256507928385|\n",
      "+--------------------+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập kiểm tra\n",
    "predictions = lr_model.transform(test_data)\n",
    "predictions.select(\"features\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE): 6.797060013251237\n",
      "R-squared (R2): 0.49382941068349395\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Tính RMSE\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator_rmse.evaluate(predictions)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "# Tính R²\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator_r2.evaluate(predictions)\n",
    "print(f\"R-squared (R2): {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 4.589382240299312\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"label\", numTrees=20)\n",
    "rf_model = rf.fit(train_data)\n",
    "predictions_rf = rf_model.transform(test_data)\n",
    "rmse_rf = evaluator_rmse.evaluate(predictions_rf)\n",
    "print(f\"Random Forest RMSE: {rmse_rf}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBT RMSE: 3.3165151342090855\n",
      "GBT R2: 0.8794912268299956\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "\n",
    "gbt = GBTRegressor(featuresCol=\"features\", labelCol=\"label\", maxIter=50)\n",
    "gbt_model = gbt.fit(train_data)\n",
    "predictions_gbt = gbt_model.transform(test_data)\n",
    "\n",
    "rmse_gbt = evaluator_rmse.evaluate(predictions_gbt)\n",
    "r2_gbt = evaluator_r2.evaluate(predictions_gbt)\n",
    "print(f\"GBT RMSE: {rmse_gbt}\")\n",
    "print(f\"GBT R2: {r2_gbt}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
